# Internet Research Agency v2
If we were to organize our own IRA, how would we do it? The mission statement is
probably to cause maximal political interference for minimal cost, and being
detected by a few people probably isn't a big deal. The primary objective is to
push the general tone of the conversation, or lend credibility to a set of
viewpoints.

## Economic optimization
There is probably a large supply of qualified candidates for a trolling
position, so my guess is that the job has a few characteristics:

- High-ish turnover
- Regular working hours, possibly accommodating college classes
- Relatively rigid guidelines/strategies for posting stuff
- Company-owned accounts, rather than individually-built
- Not a lot of accounts: each one costs something to convincingly maintain

The [IRA page](https://en.wikipedia.org/wiki/Internet_Research_Agency) suggests
that accounts are somewhat consistently assigned to users who work 12-hour
shifts every couple of days, but this seems like it would be easy to detect. I'd
be surprised if we found that type of consistency; we can look for it by finding
accounts whose posts match that submission pattern.

## Management optimization
We want to get the most out of our trolls, so we need ways to quantify and
optimize performance. First let's talk about measurement.

We can measure a troll's effectiveness in a few ways:

1. Sheer volume of content produced
2. Comment/submission score
3. Comment/submission engagement
4. Second-order engagement of individual users
5. Second-order engagement of a community
6. Overton window modification for a community

Ultimately a troll farm is going for (6), but 1-5 are varying-quality proxies
that are easier to attribute to individual employees.

## High-level strategy
A troll farm has two strategic goals: create and amplify a haven for the desired
form of extremism, and subtly shift moderate communities towards those extremes.
Reddit itself already does the former simply due to its community-oriented
organization; subreddits often have rules indicating that posts should be
aligned with, or at least not challenge, a given viewpoint, and moderators have
broad authority to ban users.

You can shift a moderate community in a couple of ways. One strategy is to
slowly and politely introduce well-argued views, creating the impression that
the most thoughtful users think in the desired way. Another approach would be to
have trolls that poorly or rudely defended the established viewpoint, and let
users (or other trolls) correct them, hopefully changing their views in the
process.

Shifting moderates is a riskier and longer-term strategy that's difficult to
measure; it wouldn't surprise me if most troll farms avoided it just for those
reasons. I'm also not sure it provides very good returns: ISIS recruits
extremists through radicalization communities, and those extremists then become
recruiters. I could easily imagine radicalization being a higher-return strategy
than trying to move moderates directly.
